---
title: "CS6375: Machine Learning"
collection: teaching
type: "3 Credit Course"
permalink: /teaching/2018-fall-CS6375
venue: "JO 3.516"
date: 2018-01-01
location: "UT Dallas"
---
Fall 2018


Course Overview
======
**Class Hours**: Tu/Th 4:00â€“5:15pm <br> **Class Room**: JO 3.516 <br>

Instructor: Gautam Kunapuli <br>
Office: ECSS 2.717 <br>
Email:  gautam-dot-kunapuli-@-utdallas.edu <br>
Office Hours: Wed 12pm-1pm, and by appointment. <br>

Teaching Assistant: TBA <br>
Office: TBA <br> 
Email: TBA <br>
Office Hours:  TBA <br>

Course Description
-----
The main aim of the course is to provide an introduction and **hands-on experience and understanding**
of a broad variety of **machine-learning algorithms** on **real applications**. In addition to delving into the underlying mathematical and/or algorithmic details for many learning algorithms, we will also explore the practical aspects of applying machine learning to real-world data through **programming assignments**.

**Pre-requisities:** The mandatory pre-requisite is **CS5343: Algorithm Analysis and Data Structures**. 

In addition, many concepts in this class require a comfortable grasp of basic **probability theory**, **linear algebra**, **multivariate calculus** and **optimization**. Garret Thomas' _Mathematics for Machine Learning_ is a superb review of essential mathematical background, both to review and as a quick reference; you can read it [here](https://gwthomas.github.io/docs/math4ml.pdf).

The programming assignments will require coding in **Python**.

**Textbooks and Course Materials:**
There is **no required textbook** for this class. However, the following textbooks are useful references for various topics we will cover in this course:
* _Pattern Recognition and Machine Learning_ by Christopher M. Bishop; this is a standard textbook and reference for introductory
machine learning and covers a large part of our syllabus;
* _Machine Learning: a Probabilistic Perspective_ by Kevin Murphy; another excellent book and reference, especially for probabilistic
graphical models.

The following books are available online, free for personal use. Supplemental reading material will be assigned from these sources
as often as possible.
* _Bayesian Reasoning and Machine Learning_ by David Barber (available [online](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online))
* _Understanding Machine Learning: From Theory to Algorithms_ by Shai Shalev-Shwartz and Shai Ben-David (available [online](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)) introduces machine learning from a theoretical perspective;
* _Deep Learning_ by Ian Goodfellow, Yoshua Bengio and Aaron Courville (available [online](https://www.deeplearningbook.org/)) is an excellent introductory textbook for a wide-variety of deep learning methods and applications;
* _Reinforcement Learning: An Introduction_ by Richard S. Sutton and Andrew G. Barto (available [online](http://incompleteideas.net/book/the-book-2nd.html)) is the _de facto_ textbook and reference for reinforcement learning;


**Grading policy:** TBA


Course Policies
=====
**Attendance policy:**
Classroom attendance for all lectures is mandatory. Prolonged absence from the lectures may lead to substantial grade penalties:
* two consecutive absences, no penalty;
* 3 consecutive absences: 1 letter grade drop;
* 4 consecutive absences, F grade.

Absence due to emergency or extenuating circumstances can be excused, but [proof may be required](http://cs.utdallas.edu/education/undergraduate/attendance-policy/).

**Homework policy:** Homework assignments are **due at the start of class on the due date** without exceptions, unless permission was obtained from the instructor **in advance**. Homework and assignment deadlines will  not be extended except under extreme university-wide circumstances such as weather emergencies.

All homeworks, programming projects, take-home exams (if any) **are to be written up and completed individually**. You **may discuss, collaborate, brainstorm and strategize** ideas, concepts and problems with other students. However, all written solutions and coded programs **must be your own**. Copying another student's work or allowing other students to copy your work is academically dishonest.

**Academic Integrity:**
All students are responsible for adhering to UT Dallas Community Standards and Conduct, particularly regarding [Academic Integrity](https://www.utdallas.edu/conduct/integrity/) and [Academic Dishonesty](https://www.utdallas.edu/conduct/dishonesty/).  Any academic dishonesty, including, but not restricted to [plagiarism](https://www.utdallas.edu/conduct/dishonesty/#plagiarism) (including from internet sources), [collusion](https://www.utdallas.edu/conduct/dishonesty/#collusion), [cheating](https://www.utdallas.edu/conduct/dishonesty/#cheating), [fabrication](https://www.utdallas.edu/conduct/dishonesty/#fabrication), will result in a zero score on the assignment/project/exam and possible disciplinary action.

**Students with Disabilities:**
The University of Texas at Dallas is committed to equal access in all endeavors for students with disabilities. The [Office of Student Accessability (OSA)](https://www.utdallas.edu/studentaccess/) provides academic accommodations for eligible students with a documented disability. Accommodations for each student are determined by OSA on an individual basis, with input from qualified professionals. Accommodations are intended to level the playing field for students with disabilities, while maintaining the academic integrity and standards set by the University. If you think you qualify for an academic accommodation, please visit OSA to determine eligibility. 

If you have already qualified for an academic accommodation, please contact me by e-mail to schedule an appointment **before classes start**, if possible.

Syllabus and Schedule
======
Slides and other course materials will be posted here.

<!--table border="1" cellspacing="0" cellpadding="0">
  <tbody><tr>
    <td width="117" valign="top"><p align="center"><em><strong>Week</strong></em></p></td>
    <td width="321" valign="top"><p align="center"><strong><em>Topic </em></strong></p></td>
    <td width="321" valign="top"><div align="center"><em><strong>Reading</strong></em></div></td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 1</p></td>
    <td width="321" valign="top">Introduction &amp; Features</td>
    <td width="321" valign="top"><a href="/natarasr/Courses/AML/Readings/FeatureSelection.pdf">Feature Selection</a></td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 2</p></td>
    <td width="321" valign="top"><p>Evaluation Methodology &amp; Decision Trees (HW1 Out)</p></td>
    <td width="321" valign="top">Chapter 3 of Mitchell Book </td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 3</p></td>
    <td width="321" valign="top"><p>Support Vector Machines(HW1 due &amp; PA1 Out)</p></td>
    <td width="321" valign="top"><a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf">Andrew Ng's class notes</a></td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 4</p></td>
    <td width="321" valign="top"><p>Decision Trees and SVM wrap up</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 5</p></td>
    <td width="321" valign="top"><p>Logistic Regression (PA1 due &amp; HW2 Out) &amp; Naive Bayes</p></td>
    <td width="321" valign="top"><a href="http://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf">Chapter 3 of Mitchell Book </a></td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 6</p></td>
    <td width="321" valign="top"><p>Nearest Neighbors &amp; Bias variance Analysis (PA 2 out)</p></td>
    <td width="321" valign="top">See onestart for reading materials</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 7</p></td>
    <td width="321" valign="top"><p>Ensemble Methods (HW3 due)</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 8</p></td>
    <td width="321" valign="top"><p><strong>Mid-term 1 </strong></p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>&nbsp; 9</p></td>
    <td width="321" valign="top"><p>Ensemble Methods  (PA2 Due)</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>10</p></td>
    <td width="321" valign="top"><p>Talk by Dev and Introduction to RL (HW4 due)</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>11</p></td>
    <td width="321" valign="top"><p>RL Continued</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>12</p></td>
    <td width="321" valign="top"><p>Unsupervised Learning </p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>13</p></td>
    <td width="321" valign="top"><p>Unsupervised Learning WrapUp(PA 3 due)</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p> 11/25</p></td>
    <td width="321" valign="top"><p>THANKSGIVING   BREAK </p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>14</p></td>
    <td width="321" valign="top"><p>Project Presentations (HW5 due)</p></td>
    <td width="321" valign="top">&nbsp;</td>
  </tr>
  <tr>
    <td width="117" valign="top"><p>15</p></td>
    <td width="321" valign="top">Projects due, Final Exam and Wrap Up</td>
    <td width="321" valign="top"><p>&nbsp;</p></td>
  </tr>
</tbody></table-->



Homeworks, Exams and Other Materials
======





